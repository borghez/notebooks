{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea.Bagante\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mistral-d3nwVr9u-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:10<00:00,  1.80s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.50.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe all the images.\n",
      "Certainly! Here are the descriptions of the images:\n",
      "\n",
      "1. **Image 1**: This image features a close-up of a black dog with a glossy coat. The dog is looking directly at the camera with a gentle and attentive expression. The background consists of a wooden surface, which provides a rustic and warm feel to the overall image.\n",
      "\n",
      "2. **Image 2**: This image showcases a breathtaking mountain landscape. The scene is dominated by rugged, rocky peaks and lush green slopes. The mountains stretch into the distance, creating a sense of vastness and tranquility. The sky is clear, adding to the serene and majestic atmosphere of the image.\n",
      "\n",
      "3. **Image 3**: This image captures a beach scene during sunset. The sun is low on the horizon, casting a warm, golden light over the entire scene. The waves gently crash onto the shore, and the sand appears wet and reflective. The overall mood is calm and picturesque, evoking a sense of relaxation and natural beauty.\n",
      "\n",
      "4. **Image 4**: This image depicts a narrow, winding path in a lush, green landscape. The path is surrounded by tall trees and grass, creating a sense of seclusion and tranquility. The sky is clear and blue, adding to the serene and inviting atmosphere of the image.\n",
      "\n",
      "These descriptions provide a detailed overview of the content and mood of each image.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model_id = \"mistral-community/pixtral-12b\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(model_id,\n",
    "                                                      torch_dtype=torch.float16,\n",
    "                                                      device_map='cuda',\n",
    "                                                      quantization_config=quantization_config).to(\"cuda\")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "IMG_URLS = [\n",
    "\"https://picsum.photos/id/237/400/300\", \n",
    "\"https://picsum.photos/id/231/200/300\", \n",
    "\"https://picsum.photos/id/27/500/500\",\n",
    "\"https://picsum.photos/id/17/150/600\",\n",
    "]\n",
    "PROMPT = \"<s>[INST]Describe all the images.\\n[IMG][IMG][IMG][IMG][/INST]\"\n",
    "\n",
    "inputs = processor(text=PROMPT, images=IMG_URLS, return_tensors=\"pt\").to(\"cuda\")\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.45s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST]Describe this image in one sentence.[IMG][/INST]\n",
      "Describe this image in one sentence.A black dog with a collar is lying on a wooden floor, looking directly at the camera with an attentive expression.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model_id = \"mistral-community/pixtral-12b\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(model_id,\n",
    "                                                      torch_dtype=torch.float16,\n",
    "                                                      device_map='cuda',\n",
    "                                                      quantization_config=quantization_config)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "prompt = \"Describe this image in one sentence.\"\n",
    "image_url = \"https://picsum.photos/id/237/200/300\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"text\", \"content\": prompt},\n",
    "        {\"type\": \"image\"},\n",
    "      ],\n",
    "    },\n",
    "]\n",
    "\n",
    "text_prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=text_prompt, images=[image_url], return_tensors=\"pt\").to(model.device)\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "\n",
    "print(text_prompt)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  2.09s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering both photos, can this animal live here? Explain why yes or not.Based on the two photos provided, it is not likely that the animal (a black dog) lives in the environment depicted in the second photo.\n",
      "\n",
      "**Reasoning:**\n",
      "\n",
      "1. **Environmental Context:**\n",
      "   - The second photo shows a snowy landscape with a house or building in the distance, suggesting a cold, possibly remote, and high-altitude location.\n",
      "   - The first photo shows the black dog in a more typical indoor or sheltered environment, which is more likely to be a home or a place where the dog is taken care of.\n",
      "\n",
      "2. **Climate Suitability:**\n",
      "   - The dog in the first photo is a black dog, which might not be well-suited to extremely cold environments. Black dogs can absorb more heat from the sun, but they might not fare well in very cold conditions without proper insulation or care.\n",
      "\n",
      "3. **Likelihood of Residence:**\n",
      "   - The second photo does not show any signs of a dog or any other domestic animals, which suggests that the area might not be inhabited by animals typically kept as pets.\n",
      "   - The first photo shows the dog in a more typical living environment for a pet, indicating that the dog is more likely to reside in a warmer, more hospitable climate.\n",
      "\n",
      "Therefore, based on the provided photos, it is more likely that the black dog lives in the environment depicted in the first photo rather than the snowy landscape shown in the second photo.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model_id = \"mistral-community/pixtral-12b\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(model_id,\n",
    "                                                      torch_dtype=torch.float16,\n",
    "                                                      device_map='cuda',\n",
    "                                                      quantization_config=quantization_config).to(\"cuda\")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "url_dog = \"https://picsum.photos/id/237/200/300\"\n",
    "url_mountain = \"https://picsum.photos/seed/picsum/200/300\"\n",
    "\n",
    "chat = [\n",
    "    {\n",
    "      \"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"text\", \"content\": \"Considering both photos, can this animal \"}, \n",
    "        {\"type\": \"image\"}, \n",
    "        {\"type\": \"text\", \"content\": \"live here? Explain why yes or not.\"}, \n",
    "        {\"type\": \"image\"}\n",
    "      ]\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(chat)\n",
    "inputs = processor(text=prompt, images=[url_dog, url_mountain], return_tensors=\"pt\").to(model.device)\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows two Italian identification cards on a white surface. The card in the top right corner is partially visible, while the one in the bottom left corner is fully visible.\n",
      "\n",
      "**Card 1 (Top Right):**\n",
      "\n",
      "* A woman's face is visible at the top of the card.\n",
      "* The name \"EMMA\" is written below her photo.\n",
      "* Below that, there are several lines of text, including:\n",
      "\t+ \"ROMA\" (Rome) and a date: \"14.12.1998\"\n",
      "\t+ A citizenship stamp: \"CITADINANZA ITALIANA\"\n",
      "\t+ A series of numbers: \"065640\"\n",
      "\n",
      "**Card 2 (Bottom Left):**\n",
      "\n",
      "* The card has a blue background with white text.\n",
      "* At the top, it says \"REPUBBLICA ITALIANA\" and \"MINISTERO DELL'INTERNO\".\n",
      "* Below that, there is more text, including:\n",
      "\t+ \"CARTA DI IDENTITA'/IDENTITY CARD\"\n",
      "\t+ A series of numbers: \"CA92732FS\"\n",
      "\t+ The name \"ROMA\" (Rome) and a date: \"30.12.2019\"\n",
      "\n",
      "Overall, the image appears to be a close-up view of two Italian identification cards, possibly for travel or official purposes.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "response = ollama.chat(\n",
    "        model='llama3.2-vision', #llava #llama3.2-vision #minicpm-v\n",
    "        messages=[\n",
    "                {\n",
    "                        'role': 'user',\n",
    "                        'content': 'Act as an OCR. Analyze the provided image and: 1. Recognize all visible text in the image as accurately as possible. 2. Maintain the original structure and formatting of the text. 3. If any words or phrases are unclear, indicate this with [unclear] in your transcription. 4. Provide only the transcription without any additional comments. Just writte the transcription, no comments or other text! Reember to DO NOT add any other text or comment other than the transcription!',\n",
    "                        'images': [\"C:\\\\Users\\\\Andrea.Bagante\\\\Desktop\\\\CI\\\\CI_emma_storta_1.jpg\"],\n",
    "                        }],\n",
    "                        )\n",
    "result = response['message']['content']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_simple_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-d3nwVr9u-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
